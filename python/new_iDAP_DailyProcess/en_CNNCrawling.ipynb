{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymysql\n",
    "from datetime import datetime, timedelta,timezone\n",
    "from google_trans_new import google_translator\n",
    "import time\n",
    "import random\n",
    "\n",
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def gl_translator(text, lang_src, lang_tgt) :\n",
    "    url_suffix_list = ['ac','ad','ae','al','am','as','at','az','ba','be','bf','bg','bi','bj','bs','bt','by','ca','cat','cc','cd','cf','cg','ch','ci','cl','cm','cn','co.ao','co.bw','co.ck','co.cr','co.id','co.il','co.in','co.jp','co.ke','co.kr','co.ls','co.ma','co.mz','co.nz','co.th','co.tz','co.ug','co.uk','co.uz','co.ve','co.vi','co.za','co.zm','co.zw','co','com.af','com.ag','com.ai','com.ar','com.au','com.bd','com.bh','com.bn','com.bo','com.br','com.bz','com.co','com.cu','com.cy','com.do','com.ec','com.eg','com.et','com.fj','com.gh','com.gi','com.gt','com.hk','com.jm','com.kh','com.kw','com.lb','com.lc','com.ly','com.mm','com.mt','com.mx','com.my','com.na','com.ng','com.ni','com.np','com.om','com.pa','com.pe','com.pg','com.ph','com.pk','com.pr','com.py','com.qa','com.sa','com.sb','com.sg','com.sl','com.sv','com.tj','com.tr','com.tw','com.ua','com.uy','com.vc','com.vn','com','cv','cx','cz','de','dj','dk','dm','dz','ee','es','eu','fi','fm','fr','ga','ge','gf','gg','gl','gm','gp','gr','gy','hn','hr','ht','hu','ie','im','io','iq','is','it','je','jo','kg','ki','kz','la','li','lk','lt','lu','lv','md','me','mg','mk','ml','mn','ms','mu','mv','mw','ne','nf','nl','no','nr','nu','pl','pn','ps','pt','ro','rs','ru','rw','sc','se','sh','si','sk','sm','sn','so','sr','st','td','tg','tk','tl','tm','tn','to','tt','us','vg','vu','ws']\n",
    "    isSuccess = False\n",
    "    url_suffix_inx = random.randint(0, len(url_suffix_list)-1)\n",
    "    content_tw = ''\n",
    "    while isSuccess == False :\n",
    "        try :\n",
    "            translator = google_translator(url_suffix=url_suffix_list[url_suffix_inx])        \n",
    "            content_tw = translator.translate(text, lang_src=lang_src, lang_tgt=lang_tgt)\n",
    "            isSuccess = True\n",
    "        except Exception as e:\n",
    "            url_suffix_inx = random.randint(0, len(url_suffix_list)-1)\n",
    "    return content_tw    \n",
    "\n",
    "def WebCrawling(days=5):\n",
    "    host = '10.55.23.101'\n",
    "    port = 33060\n",
    "    user = 'root'\n",
    "    passwd = \"1234\"\n",
    "    db = 'idap'\n",
    "\n",
    "    showPrintMSG = 1 # 0:不呈現，1:呈現 debug mode\n",
    "    archiveDate = 10\n",
    "    web = 'cnn'\n",
    "    language = 'en'\n",
    "    sleep_sec = 2\n",
    "    lang_src=language\n",
    "    lang_tgt='zh-tw'\n",
    "\n",
    "    conn = pymysql.connect(host=host, port=port,user=user, passwd=passwd, db=db)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    baseUrl = 'https://edition.cnn.com'\n",
    "    InitUrl = 'https://edition.cnn.com/business'\n",
    "    res = requests.get(InitUrl)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    newsList = soup.select(\"div.zn__containers li\")\n",
    "    deleteFromDate = datetime.strftime(datetime.now() - timedelta(archiveDate), '%Y%m%d')\n",
    "    dt1 = datetime.utcnow().replace(tzinfo=timezone.utc)\n",
    "    creationdate = dt1.astimezone(timezone(timedelta(hours=8))).strftime('%Y/%m/%d %H:%M:%S')  # 轉換時區 -> 東八區\n",
    "\n",
    "    c = 0\n",
    "    for i in range(0,len(newsList)):\n",
    "        try:\n",
    "            title = soup.select(\"div.zn__containers li a\")[i].text\n",
    "            if title == '' :\n",
    "                title = soup.select(\"h1.pg-headline\")[0].text\n",
    "            url = baseUrl+soup.select(\"div.zn__containers li a\")[i].get('href')\n",
    "            cur.execute('select count(1) from news_daily_source where url=%s',(url))\n",
    "            if cur.fetchone()[0] == 0 :\n",
    "                if RepresentsInt(url.split('/')[3]) :\n",
    "                    publishdate = url.split('/')[3]+url.split('/')[4]+url.split('/')[5]\n",
    "                    if int(publishdate) > int(deleteFromDate) :\n",
    "                        resContent = requests.get(url)\n",
    "                        soupContent = BeautifulSoup(resContent.text, 'html.parser')\n",
    "                        divList = soupContent.select(\"div.zn-body__paragraph\")\n",
    "                        if len(divList) > 0 :\n",
    "                            divList = soupContent.select(\"div.zn-body__paragraph\")\n",
    "\n",
    "                            tag = url.split('/')[6]\n",
    "                            content = ''.join([c.text.strip() for c in divList])\n",
    "                            content_tw = gl_translator(content, lang_src, lang_tgt)\n",
    "                            title_tw = gl_translator(title, lang_src, lang_tgt) \n",
    "                            #print(i,'\\n title:', title, '\\n publishdate:',publishdate, '\\n tag:',tag,'\\n url:', url)\n",
    "                            cur.execute('insert into news_daily_source(web, title, title_tw, content, content_tw, publishdate, url, creationdate,language,tag)values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)',(web, title, title_tw, content, content_tw, publishdate, url, creationdate,language,tag))\n",
    "                            cur.execute('commit')\n",
    "                            c = c + 1\n",
    "        except Exception as e:\n",
    "            print('Exception CNNCrawling:'+str(e)) \n",
    "    print('CNN ',creationdate,' total:',c)\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

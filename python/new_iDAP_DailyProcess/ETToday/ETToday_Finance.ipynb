{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob.liang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1364, \"Field 'id' doesn't have a default value\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETToday_Finance  2021-01-31 21:54:11.670810  total: 83\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 網站名稱：ET TODAY\n",
    "# 網址： https://finance.ettoday.net/focus/104\n",
    "# 爬取類型： 財經最新\n",
    "# 爬取範圍： 今日、昨日\n",
    "#############################################\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import pymysql\n",
    "import requests\n",
    "\n",
    "def WebCrawling(days = 2):\n",
    "    host = '10.55.23.101'\n",
    "    port = 33060\n",
    "    host = '127.0.0.1'\n",
    "    port = 3306\n",
    "    user = 'root'\n",
    "    passwd = \"1234\"\n",
    "    db = 'idap'\n",
    "    web = \"ETToday_Finance\" \n",
    "    tag = \"Finance\"\n",
    "    \n",
    "    targetUrl = \"https://finance.ettoday.net/focus/104/{}\"\n",
    "    page = 1\n",
    "    lastPageDesc = ''\n",
    "    \n",
    "    try:\n",
    "        conn = pymysql.connect(host=host, port=port, user=user, passwd=passwd, db=db)\n",
    "        cur = conn.cursor()\n",
    "        c=0\n",
    "        while(True):\n",
    "            res = requests.get(targetUrl.format(page))\n",
    "            res.encoding = 'utf-8'\n",
    "            if res.status_code == 200:\n",
    "                soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "                currentPageDesc = soup.select('#finance > div.wrapper_box > div > div.container_box > div > div > div.c1 > div.part_pager_1 > p')[0].text\n",
    "                if lastPageDesc == currentPageDesc:\n",
    "                    break\n",
    "\n",
    "                news = soup.select('a.piece.clearfix')\n",
    "                for new in news:\n",
    "                    publishdate = new.select('p.date')[0].text.strip()\n",
    "                    if '-' not in publishdate:\n",
    "                        publishdate = datetime.now().strftime('%Y%m%d')\n",
    "                    else:\n",
    "                        publishdate = publishdate.split(' ')[0].replace('-', '')\n",
    "\n",
    "                    if publishdate < (datetime.today() - timedelta(days=days)).strftime('%Y%m%d'):    \n",
    "                        break\n",
    "\n",
    "                    title = new.select('h3')[0].text.strip()\n",
    "                    url = new.get('href')\n",
    "                    creationdate = datetime.now()\n",
    "                    content = ''\n",
    "\n",
    "                    contentres = requests.get(url)\n",
    "                    contentres.encoding = 'utf-8'\n",
    "                    if contentres.status_code == 200:\n",
    "                        contentsoup = BeautifulSoup(contentres.text, 'html.parser')\n",
    "                        contents = contentsoup.select('div.story > p')\n",
    "                        content = ' '.join([c.text.strip() for c in contents])\n",
    "                        contentres.close()\n",
    "                        cur.execute('select count(1) from news_daily where url=%s',(url))\n",
    "                        if cur.fetchone()[0] == 0 :\n",
    "                            cur.execute('insert ignore into news_daily(web, title, content, tag, publishdate, url, creationdate)values(%s, %s, %s, %s, %s, %s, %s)', (web, title, content, tag, publishdate, url, creationdate))\n",
    "                            cur.execute('commit')\n",
    "                            c=c+1\n",
    "            res.close()\n",
    "            page += 1\n",
    "            lastPageDesc = currentPageDesc\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print('Exception ETToday_Finance:'+str(e))\n",
    "    print('ETToday_Finance ',creationdate,' total:',c)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    WebCrawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
